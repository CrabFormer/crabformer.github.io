<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CrabFormer: RGB-D Segmentation and Pose Estimation</title>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    
    <style>
        /* General Page Layout and Typography */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 40px auto;
            padding: 20px;
            border: 1px solid #ddd;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            /* Ensure the main text flow starts on the left */
            text-align: left; 
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            /* Main title is typically centered for papers */
            text-align: center; 
        }
        h2 {
            color: #3498db;
            margin-top: 30px;
            border-left: 4px solid #e74c3c;
            padding-left: 10px;
        }
        .authors, .affiliations {
            font-size: 0.9em;
            margin-bottom: 10px;
            /* Align authors/affiliations to the left */
            text-align: left; 
        }
        
        /* Abstract Block Styling */
        .abstract-content {
            background-color: #f9f9f9;
            padding: 20px;
            border-left: 5px solid #e74c3c;
            border-radius: 0 8px 8px 0;
            text-align: justify; /* Use justified for a professional abstract look */
        }
        .keywords {
            font-style: italic;
            font-size: 0.9em;
            margin-top: 20px;
            /* Keywords aligned left */
            text-align: left; 
            padding-top: 10px;
            border-top: 1px dashed #ccc;
        }

        /* BUTTON STYLING (Kept centered) */
        .publication-links {
            text-align: center; /* KEEP the buttons centered */
            margin: 20px 0;
            padding: 10px 0;
        }
        .link-block {
            display: inline-block;
            margin: 5px 10px;
        }
        .button {
            display: inline-flex;
            align-items: center;
            padding: 10px 20px;
            font-size: 16px;
            font-weight: bold;
            text-decoration: none;
            transition: background-color 0.3s, box-shadow 0.3s;
        }
        .is-rounded {
            border-radius: 290486px;
        }
        .is-dark {
            background-color: #2c3e50;
            color: #ffffff;
            border: 1px solid #2c3e50;
        }
        .is-dark:hover {
            background-color: #34495e;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }
        .icon {
            margin-right: 8px;
        }
        /* FIGURE SPECIFIC STYLING */
        figure {
            margin: 40px auto;
            padding: 0;
            max-width: 800px;
        }
        figure img {
            max-width: 100%;
            height: auto;
            display: block; /* Important for centering */
            margin: 0 auto;
            border: 1px solid #ccc;
            border-radius: 4px;
        }
        figcaption {
            margin-top: 10px;
            font-size: 0.9em;
            color: #555;
            text-align: left;
            line-height: 1.4;
        }
    </style>
</head>
<body>

    <h1>CrabFormer: RGB-D Segmentation and Pose Estimation for Front-End Loading of Piled Chesapeake Blue Crabs</h1>

    <div>
        <div class="authors">
            <strong>Mohamed Amr Ali</strong> <sup>a, b, *</sup>,
            <strong>Faranguisse Sadrieh</strong> <sup>a, b</sup>,
            <strong>Benjamin Wu</strong> <sup>a</sup>,
            <strong>Yang Tao</strong> <sup>a, b, *</sup>
        </div>

        <div class="affiliations">
            <p><sup>a</sup> Fischell Department of Bioengineering, University of Maryland, College Park, MD 20742, USA</p>
            <p><sup>b</sup> Maryland Robotics Center, University of Maryland, College Park, MD 20742, USA</p>
            <p>* mali93@terpmail.umd.edu, ytao@umd.edu</p>
        </div>
    </div>


    <div class="publication-links">
        <span class="link-block">
            <a href="https://drive.google.com/drive/folders/1S5V2TyP17qsbI0zZ9q36L6H6u5UMq9EI?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
            </a>
        </span>

        <span class="link-block">
            <a href="https://drive.google.com/file/d/1kGXAEmoUV1kzGXWCfuzT2foxEfEdWBBT/view?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-database"></i></span>
                <span>Dataset</span>
            </a>
        </span>
        
        <span class="link-block">
            <a href="https://drive.google.com/drive/folders/1X8oFIOFW7ivDsIMjctZJW7mDrv8ZzTvM?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-tag"></i></span>
                <span>Labels</span>
            </a>
        </span>

        <span class="link-block">
            <a href="https://drive.google.com/drive/folders/1QRJeXloaJqVYtjGg9SpInlCcsaEZMrUU?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-download"></i></span>
                <span>Trained Model Weights</span>
            </a>
        </span>
    </div>

    <hr>
    <h2>Figures and Results</h2>

    <figure>
        <img src="images/Figure_1-System overview.png" alt="Diagram illustrating the front-end loading system for crab processing." loading="lazy">
        <figcaption>
            <strong>Figure 1: System overview.</strong> A diagram illustrating the front-end loading task to a custom crab processing machine. Crabs are piled on a loading table, where laser scanners and a CMOS camera scan them to capture depth information and RGB images. This data is used to determine the correct orientation and positioning of the crabs before they are transferred to the crab processing machine for further disassembly. The system aims to automate the labor-intensive crab loading.
        </figcaption>
    </figure>

    <figure>
        <img src="images/Figure_2-Dataset.png" alt="Example images of discrete, overlapping, and piled crab configurations from the dataset." loading="lazy">
        <figcaption>
            <strong>Figure 2: Dataset Examples.</strong> Example images of different crab configurations from the dataset used to train the CrabFormer model. (Left) Discrete: crabs are well separated with no overlap. (Middle) Overlapping: crabs partially overlap, creating a more complex segmentation task. (Right) Piled: crabs are stacked on each other, presenting the most challenging case for instance segmentation and pose estimation.
        </figcaption>
    </figure>

    <figure>
        <img src="images/Figure_3-CrabFormer Model.png" alt="Architecture of the CrabFormer model for RGB-D instance segmentation and keypoint prediction." loading="lazy">
        <figcaption>
            <strong>Figure 3: CrabFormer Model Architecture.</strong> The architecture of the CrabFormer model for RGB-D instance segmentation and keypoint prediction. The backbone is a feature extractor, passing features to the pixel decoder, which employs a multi-scale deformable attention transformer. The multi-scale masked-attention transformer decoder generates masks, keypoints, classes, and scores from query features and learnable positional embeddings.
        </figcaption>
    </figure>

    <figure>
        <img src="images/Figure_4-Backbone_types.png" alt="Comparison of fusion strategies for RGB-D data: Early, Intermediate, and Late Fusion." loading="lazy">
        <figcaption>
            <strong>Figure 4: Backbone Fusion Comparison.</strong> Comparison of fusion strategies for RGB-D data in the CrabFormer model. (Left) Early Fusion: RGB and depth data are concatenated before input into the Swin transformer. (Middle) Intermediate Fusion: A dual-patch approach is employed where RGB and depth features are patched separately before concatenating and inserting into the Swin transformer. (Right) Late Fusion: RGB and depth features are processed independently through separate Swin modules and combined via addition or mean operations to form the final RGB-D feature representation.
        </figcaption>
    </figure>

    <figure>
        <img src="images/Figure_5- real world implmentation.png" alt="Hardware setup for data collection of Chesapeake blue crabs." loading="lazy">
        <figcaption>
            <strong>Figure 5: Hardware Setup.</strong> Hardware setup for data collection of Chesapeake blue crabs, including an overhead CMOS camera, dual line lasers in a galvanometric unit, and a food-safe loading tabletop. Crabs are manually offloaded onto the tabletop, and the system captures high-resolution 3D images for segmentation and pose estimation model development.
        </figcaption>
    </figure>

    <figure>
        <img src="images/Figure_6-model prediction.png" alt="Visualization of the CrabFormer model predictions across different real-world pile configurations." loading="lazy">
        <figcaption>
            <strong>Figure 6: Model Prediction Visualization.</strong> Visualization of the CrabFormer model predictions across different real-world pile configurations. Each row corresponds to a specific case: Discrete (top), Overlapping (middle), and Piled (bottom). The columns show (Left) the colored input image, (Middle) the corresponding depth map, and (Right) the model’s real-world predicted instance segmentation masks along with keypoint predictions. The keypoints are indicated with colored skeletons. The green line is between the rear left and front center keypoints, while the blue line is between the front center and rear right keypoints.
        </figcaption>
    </figure>

    <figure>
        <img src="images/Figure_7-Prioritization_v2.png" alt="Crab prioritization algorithm output highlighting the topmost crab instance." loading="lazy">
        <figcaption>
            <strong>Figure 7: Prioritization Output.</strong> (a) Colored image and (b) depth map inputs to CrabFormer, yield the (c) model outputs showing each mask in a different color, with keypoints connected by a blue skeleton between the front center and rear right keypoints, and a green skeleton between the front center and rear left keypoints. (d) Highlights the topmost crab instance in the pile after the prioritization algorithm. A blue cross marks the midpoint between the rear right and rear left keypoints, and the green vector extends from the rear midpoint to the front center to indicate the crab’s orientation.
        </figcaption>
    </figure>

    <hr>

    <h2>Abstract</h2>
    <div class="abstract-content">
        <p>CrabFormer is a multitasking transformer model developed to tackle the challenges of front-end loading in the automated processing of Chesapeake blue crabs. Existing methods often struggle to accurately identify crabs in chaotic, piled configurations, where occlusions and overlapping are common. CrabFormer addresses this by combining instance segmentation and keypoint prediction using RGB-D inputs to detect crabs and estimate their orientation. Utilizing a dual-patch Swin-T backbone, the model processes RGB and depth data separately, effectively capturing visual and geometric features. CrabFormer is evaluated on a custom dataset comprising discrete, overlapping, and piled crabs. It achieves a segmentation Average Precision (AP) of 67.84 and Average Recall (AR) of 76.29, while its keypoint prediction AP and AR are 62.43 and 77.23, respectively. The model outperforms state-of-the-art transformer-based segmentation and keypoint prediction models, particularly in the most complex piled cases, demonstrating improvements in both AP and AR. It excels in identifying the topmost crab in a pile, a key task for automated processing. Additionally, CrabFormer achieves competitive inference times while maintaining superior multitasking performance. These results highlight CrabFormer’s potential to enhance the automation of front-end loading in the seafood industry, reducing labor reliance and improving operational efficiency. Future work will expand the dataset and explore the model’s applicability to other crustaceans with similar morphological complexities.</p>
    </div>

    <div class="keywords">
        <strong>Keywords:</strong> Computer Vision, Front-end Loading, Instance Segmentation, Pose Estimation, Food Automation.
    </div>

</body>
</html>
